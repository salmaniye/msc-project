{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutomaticSpeechRecognitionPipeline\n",
    "\n",
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('pokemon_letsgo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66949"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['text'].str.contains('I liked a @YouTube video')== False]\n",
    "df = df[df['text'].str.contains('I added a video to a @YouTube')== False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65819"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "preprocessed_text = []\n",
    "\n",
    "for tweet in df['text']:\n",
    "    tweet_words = []\n",
    "    for word in tweet.split(' '):\n",
    "        if word.startswith('@') and len(word) > 1:\n",
    "            word = '@user'\n",
    "        elif word.startswith('http'):\n",
    "            word = 'http'\n",
    "        tweet_words.append(word)\n",
    "    tweet_proc = \" \".join(tweet_words)\n",
    "    preprocessed_text.append(tweet_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['preprocessed tweets'] = preprocessed_text\n",
    "# df.drop(columns=df.columns[0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40424    375\n",
       "57568    346\n",
       "56096    328\n",
       "45658    321\n",
       "40890    317\n",
       "        ... \n",
       "50904     11\n",
       "54459     11\n",
       "28150     10\n",
       "43706     10\n",
       "41709     10\n",
       "Name: preprocessed tweets, Length: 65819, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "long_tweets = df['preprocessed tweets'].str.len().sort_values(ascending=False)\n",
    "\n",
    "long_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40424    375\n",
       "57568    346\n",
       "56096    328\n",
       "45658    321\n",
       "40890    317\n",
       "35178    314\n",
       "49857    308\n",
       "33029    306\n",
       "49486    302\n",
       "55398    302\n",
       "62856    301\n",
       "51055    300\n",
       "42818    300\n",
       "11640    300\n",
       "45224    298\n",
       "40414    298\n",
       "40696    298\n",
       "63303    297\n",
       "9074     297\n",
       "53186    297\n",
       "Name: preprocessed tweets, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_tweets.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[40424,'preprocessed tweets'] = \"Ohhh I'll play! 4 upcoming things I'm excited for. Tag 4 peeps.  ðŸŒ¼ðŸŒºðŸŒ·\\n\\n1. Assassin's Creed Odyssey (pc)\\n2. Pokemon Lets' Go (switch)\\n3. Stellaris Le Guin update (pc)\\n4. Age of Wonders Planetfall (pc)\\n\\n@CivCat @user @user @user\"\n",
    "df.at[57568,'preprocessed tweets'] = \"lets go focuses heavily on pokemon go aspects, its been theorized that this is nintendos way of trying to transition pokemon go players to this hybrid game to hopefully convince them to play the new gen 8 2019 core game. like a smooth transition. Go -&gt; Go/Core hybrid -&gt; Core game\"\n",
    "df.at[56096,'preprocessed tweets'] = \"Core series means it takes place within the main Timeline/Storyline. Main series includes core games and a few others that link in. Pokemon Lets go is hybrid of Core/SpinOff. it implements the design of a core game with the mechanics of a spin-off, its a hybrid\"\n",
    "df.at[45658,'preprocessed tweets'] = \"Venusaur's ride setting is LAND. That's what I said. \\n\\n~ Which meant Ride or Following Behind \\n~ Game Freak choose Following Behind\\n\\nCharizard is AIR \\nBlastoise is SEA \\n\\nI even included some Emojis in the leak.\\nYou have to decide which one to have first. \\n#PokemonLetsGO #Venusaur http\"\n",
    "df.at[40890,'preprocessed tweets'] = \"Game Freak lost the picture with #PokemonLetsGo. They need to realize who their fans are and prove they are not so out of touch with us all. This game only shows they dont know the fans anymore. Every time news for LetsGo drops, more I see talking out against it.\"\n",
    "df.at[35178,'preprocessed tweets'] = \"Lets go is confirmed not a core game but instead a spin off the next core game is next year and lets go comes out november 16 or 17 i forget but not october also the point of lets go is to bring in fans of pkmn go and ease them into the main games and core mechanics\"\n",
    "df.at[49857,'preprocessed tweets'] = \"But Nintendo's stock has tumbled in price over the past couple of months as the sales of the switch has slowed dramaticly because the only big games that are coming soon are Pokemon lets go (mixed reactions) and smash which didn't help the Wii u's sales half as much as predicted http\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "\n",
    "roberta = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "#roberta = \"cardiffnlp/twitter-roberta-base-2021-124m\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(roberta)\n",
    "tokenizer = AutoTokenizer.from_pretrained(roberta)\n",
    "\n",
    "labels = ['Negative', 'Neutral', 'Positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_scores = []\n",
    "\n",
    "for processed_tweet in df['preprocessed tweets']:\n",
    "    encoded_tweet = tokenizer(processed_tweet, return_tensors='pt')\n",
    "\n",
    "    output = model(**encoded_tweet)\n",
    "\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "\n",
    "    sentiment_scores.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment scores'] = sentiment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Negative', 'Neutral', 'Positive']\n",
    "index_no = [0,1,2]\n",
    "\n",
    "label_dict = dict(zip(index_no, labels))\n",
    "\n",
    "overall_sentiment = []\n",
    "\n",
    "for sentiment_score in df['sentiment scores']:\n",
    "    overall_sentiment.append(label_dict.get(sentiment_score.argmax()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = overall_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('pokemon_letsgo_tweets_datatset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
